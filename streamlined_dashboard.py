#!/usr/bin/env python3
"""
0xBot Signal Analysis Platform - Streamlined Web Interface
Focus on signal upload, analysis, and advanced wallet/deployer intelligence
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import requests
from datetime import datetime, timedelta
import asyncio
import aiohttp
from real_blockchain_analyzer import RealBlockchainAnalyzer
import re
import time
from typing import Dict, List, Optional
import asyncio

# Configure Streamlit
st.set_page_config(
    page_title="0xBot - Signal Analysis Platform",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Import existing analyzers
try:
    from realtime_signal_analyzer import RealtimeSignalAnalyzer
    from enhanced_signal_processor import EnhancedSignalProcessor
except ImportError:
    st.error("‚ö†Ô∏è Required analyzer modules not found. Please ensure all files are present.")
    RealtimeSignalAnalyzer = None
    EnhancedSignalProcessor = None

class StreamlinedSignalDashboard:
    def __init__(self):
        self.load_analyzers()
        self.setup_session_state()
    
    def load_analyzers(self):
        """Load analysis engines"""
        try:
            if RealtimeSignalAnalyzer is not None and EnhancedSignalProcessor is not None:
                self.signal_analyzer = RealtimeSignalAnalyzer()
                self.enhanced_processor = EnhancedSignalProcessor()
                self.signal_analyzer.load_model_and_insights()
                st.sidebar.success("‚úÖ AI Models loaded")
            else:
                st.sidebar.warning("‚ö†Ô∏è AI modules not available - using demo mode")
                self.signal_analyzer = None
                self.enhanced_processor = None
        except Exception as e:
            st.sidebar.error(f"‚ùå Error loading models: {e}")
            self.signal_analyzer = None
            self.enhanced_processor = None
    
    def setup_session_state(self):
        """Initialize session state"""
        if 'analyzed_signals' not in st.session_state:
            st.session_state.analyzed_signals = []
        if 'training_data' not in st.session_state:
            st.session_state.training_data = []
    
    def parse_signal_message(self, message: str) -> Dict:
        """Parse Telegram signal message into structured data"""
        signal_data = {
            'message': message,
            'timestamp': datetime.now(),
            'parsed_data': {}
        }
        
        # Extract strategy
        strategy_match = re.search(r'(Viper Vision|Cobra Scan|Alpha Hunter|Eagle Eye)', message)
        if strategy_match:
            signal_data['parsed_data']['strategy'] = strategy_match.group(1)
        
        # Extract token name
        lines = message.split('\n')
        for line in lines[1:]:
            if line.strip() and not line.startswith(('CA:', 'MC:', 'LP:', 'Fees:', 'Top', 'Free')):
                signal_data['parsed_data']['token_name'] = line.strip()
                break
        
        # Extract contract address
        ca_match = re.search(r'CA:\s*([A-Za-z0-9]{32,})', message)
        if ca_match:
            signal_data['parsed_data']['contract_address'] = ca_match.group(1)
        
        # Extract market cap
        mc_match = re.search(r'MC:\s*\$?(\d+\.?\d*)\s*(K|M)?', message)
        if mc_match:
            mc_value = float(mc_match.group(1))
            if mc_match.group(2) == 'K':
                mc_value *= 1000
            elif mc_match.group(2) == 'M':
                mc_value *= 1000000
            signal_data['parsed_data']['market_cap'] = mc_value
        
        # Extract LP
        lp_match = re.search(r'LP:\s*(\d+\.?\d*)\s*SOL', message)
        if lp_match:
            signal_data['parsed_data']['liquidity_sol'] = float(lp_match.group(1))
        
        # Extract top holders
        holders_match = re.search(r'Top\s*\d+\s*holders?:\s*(\d+)%', message)
        if holders_match:
            signal_data['parsed_data']['top_holders_percent'] = int(holders_match.group(1))
        
        # Extract LP burned status
        signal_data['parsed_data']['lp_burned'] = 'Burned' in message or 'burned' in message
        
        return signal_data
    
    def analyze_signal_comprehensive(self, signal_data: Dict) -> Dict:
        """Comprehensive signal analysis with wallet and deployer intelligence"""
        
        # Basic AI prediction
        ai_analysis = {}
        if self.signal_analyzer:
            try:
                prediction = self.signal_analyzer.analyze_signal(signal_data['message'])
                ai_analysis = prediction
            except Exception as e:
                st.warning(f"AI analysis error: {e}")
        
        # Enhanced wallet analysis
        wallet_analysis = {}
        if 'contract_address' in signal_data['parsed_data']:
            try:
                # This would call the enhanced processor in a real implementation
                wallet_analysis = self.simulate_wallet_analysis(signal_data['parsed_data']['contract_address'])
            except Exception as e:
                st.warning(f"Wallet analysis error: {e}")
        
        # Deployer intelligence
        deployer_analysis = {}
        if 'contract_address' in signal_data['parsed_data']:
            try:
                deployer_analysis = self.simulate_deployer_analysis(signal_data['parsed_data']['contract_address'])
            except Exception as e:
                st.warning(f"Deployer analysis error: {e}")
        
        # Risk assessment
        risk_score = self.calculate_comprehensive_risk(signal_data, wallet_analysis, deployer_analysis, ai_analysis)
        
        return {
            'ai_analysis': ai_analysis,
            'wallet_analysis': wallet_analysis,
            'deployer_analysis': deployer_analysis,
            'risk_score': risk_score,
            'recommendation': self.generate_recommendation(risk_score)
        }
    
    def simulate_wallet_analysis(self, contract_address: str) -> Dict:
        """Simulate advanced wallet analysis (would connect to real blockchain in production)"""
        import random
        
        return {
            'total_holders': random.randint(100, 5000),
            'top_10_percentage': random.uniform(15, 60),
            'dev_wallets': {
                'identified': random.randint(0, 5),
                'percentage': random.uniform(0, 25),
                'activity': random.choice(['Active', 'Dormant', 'Selling']),
                'risk_level': random.choice(['Low', 'Medium', 'High'])
            },
            'whale_concentration': {
                'whales_count': random.randint(2, 20),
                'largest_holder': random.uniform(5, 35),
                'risk_level': random.choice(['Low', 'Medium', 'High'])
            },
            'holder_behavior': {
                'diamond_hands_rate': random.uniform(30, 80),
                'recent_sells': random.randint(0, 50),
                'new_buyers_24h': random.randint(5, 200),
                'avg_hold_time': f"{random.uniform(1, 30):.1f} days"
            }
        }
    
    def simulate_deployer_analysis(self, contract_address: str) -> Dict:
        """Simulate deployer intelligence analysis"""
        import random
        
        return {
            'deployer_address': f"{contract_address[:8]}...{contract_address[-8:]}",
            'deployment_date': datetime.now() - timedelta(days=random.randint(1, 30)),
            'history': {
                'total_tokens': random.randint(0, 50),
                'success_rate': random.uniform(0.1, 0.9),
                'avg_performance': random.uniform(-50, 300),
                'reputation_score': random.uniform(1, 10)
            },
            'security': {
                'mint_authority': random.choice(['Disabled', 'Active']),
                'freeze_authority': random.choice(['Disabled', 'Active']),
                'contract_verified': random.choice([True, False]),
                'security_score': random.uniform(3, 10)
            },
            'patterns': {
                'launch_time_preference': random.choice(['US Hours', 'EU Hours', 'Asia Hours']),
                'funding_pattern': random.choice(['CEX', 'DEX', 'Private Wallet']),
                'typical_liquidity': f"{random.uniform(5, 100):.1f} SOL"
            }
        }
    
    def calculate_comprehensive_risk(self, signal_data: Dict, wallet_analysis: Dict, 
                                   deployer_analysis: Dict, ai_analysis: Dict) -> float:
        """Calculate comprehensive risk score (0-10, lower is better)"""
        risk_factors = []
        
        # AI prediction risk
        if ai_analysis and 'success_probability' in ai_analysis:
            ai_risk = (1 - ai_analysis['success_probability']) * 10
            risk_factors.append(ai_risk)
        
        # Wallet concentration risk
        if wallet_analysis:
            if wallet_analysis['top_10_percentage'] > 50:
                risk_factors.append(8)
            elif wallet_analysis['top_10_percentage'] > 35:
                risk_factors.append(5)
            else:
                risk_factors.append(2)
            
            # Dev wallet risk
            if wallet_analysis['dev_wallets']['percentage'] > 15:
                risk_factors.append(7)
            elif wallet_analysis['dev_wallets']['percentage'] > 5:
                risk_factors.append(4)
            else:
                risk_factors.append(1)
        
        # Deployer risk
        if deployer_analysis:
            deployer_risk = 10 - deployer_analysis['history']['reputation_score']
            risk_factors.append(deployer_risk)
            
            if deployer_analysis['security']['mint_authority'] == 'Active':
                risk_factors.append(6)
            if deployer_analysis['security']['freeze_authority'] == 'Active':
                risk_factors.append(5)
        
        # Market cap risk
        parsed_data = signal_data.get('parsed_data', {})
        if 'market_cap' in parsed_data:
            mc = parsed_data['market_cap']
            if mc < 50000:  # Under $50K
                risk_factors.append(7)
            elif mc < 100000:  # Under $100K
                risk_factors.append(4)
            else:
                risk_factors.append(2)
        
        return np.mean(risk_factors) if risk_factors else 5.0
    
    def generate_recommendation(self, risk_score: float) -> str:
        """Generate trading recommendation based on risk score"""
        if risk_score <= 3:
            return "üü¢ LOW RISK - Consider buying"
        elif risk_score <= 6:
            return "üü° MEDIUM RISK - Proceed with caution"
        else:
            return "üî¥ HIGH RISK - Avoid or use minimal position"
    
    def display_comprehensive_analysis(self, analysis: Dict, signal_data: Dict):
        """Display comprehensive analysis results"""
        
        # Main metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            risk_score = analysis['risk_score']
            risk_color = "green" if risk_score <= 3 else "orange" if risk_score <= 6 else "red"
            st.metric("Risk Score", f"{risk_score:.1f}/10", delta=None)
        
        with col2:
            if 'ai_analysis' in analysis and analysis['ai_analysis'] and 'success_probability' in analysis['ai_analysis']:
                prob = analysis['ai_analysis']['success_probability']
                st.metric("AI Success Probability", f"{prob:.1%}")
            else:
                st.metric("AI Success Probability", "N/A")
        
        with col3:
            if 'wallet_analysis' in analysis and analysis['wallet_analysis'] and 'total_holders' in analysis['wallet_analysis']:
                holders = analysis['wallet_analysis']['total_holders']
                st.metric("Total Holders", f"{holders:,}")
            else:
                st.metric("Total Holders", "N/A")
        
        with col4:
            if ('deployer_analysis' in analysis and analysis['deployer_analysis'] and 
                'history' in analysis['deployer_analysis'] and 
                'reputation_score' in analysis['deployer_analysis']['history']):
                rep_score = analysis['deployer_analysis']['history']['reputation_score']
                st.metric("Deployer Reputation", f"{rep_score:.1f}/10")
            else:
                st.metric("Deployer Reputation", "N/A")
        
        # Recommendation
        st.markdown(f"### üìä **{analysis['recommendation']}**")
        
        # Detailed analysis tabs
        tab1, tab2, tab3, tab4 = st.tabs(["üîç AI Analysis", "üí∞ Wallet Intelligence", "üë§ Deployer Analysis", "üìà Risk Breakdown"])
        
        with tab1:
            if 'ai_analysis' in analysis:
                ai_data = analysis['ai_analysis']
                if ai_data:
                    st.json(ai_data)
                else:
                    st.info("AI analysis not available for this signal")
        
        with tab2:
            if 'wallet_analysis' in analysis and analysis['wallet_analysis']:
                wallet = analysis['wallet_analysis']
                
                # Dev wallet analysis
                st.subheader("üîß Developer Wallets")
                if 'dev_wallets' in wallet:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Dev Wallets Found", wallet['dev_wallets'].get('identified', 'N/A'))
                    with col2:
                        st.metric("Dev Holdings", f"{wallet['dev_wallets'].get('percentage', 0):.1f}%")
                    with col3:
                        activity = wallet['dev_wallets'].get('activity', 'Unknown')
                        color = "green" if activity == "Dormant" else "orange" if activity == "Active" else "red"
                        st.markdown(f"**Activity:** :{color}[{activity}]")
                else:
                    st.info("Dev wallet analysis not available")
                
                # Top holders analysis
                st.subheader("üêã Whale Analysis")
                if 'whale_concentration' in wallet and 'top_10_percentage' in wallet:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Top 10 Holdings", f"{wallet.get('top_10_percentage', 0):.1f}%")
                    with col2:
                        st.metric("Whale Count", wallet['whale_concentration'].get('whales_count', 'N/A'))
                    with col3:
                        st.metric("Largest Holder", f"{wallet['whale_concentration'].get('largest_holder', 0):.1f}%")
                else:
                    st.info("Whale analysis not available")
                
                # Holder behavior
                st.subheader("üìä Holder Behavior")
                if 'holder_behavior' in wallet:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Diamond Hands", f"{wallet['holder_behavior'].get('diamond_hands_rate', 0):.1f}%")
                    with col2:
                        st.metric("Recent Sells", wallet['holder_behavior'].get('recent_sells', 'N/A'))
                    with col3:
                        st.metric("New Buyers (24h)", wallet['holder_behavior'].get('new_buyers_24h', 'N/A'))
                else:
                    st.info("Holder behavior analysis not available")
            else:
                st.info("Wallet analysis not available for this signal")
        
        with tab3:
            if 'deployer_analysis' in analysis and analysis['deployer_analysis']:
                deployer = analysis['deployer_analysis']
                
                # Deployer history
                st.subheader("üìã Deployer Track Record")
                if 'history' in deployer:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Total Tokens", deployer['history'].get('total_tokens', 'N/A'))
                    with col2:
                        success_rate = deployer['history'].get('success_rate', 0)
                        st.metric("Success Rate", f"{success_rate:.1%}")
                    with col3:
                        avg_perf = deployer['history'].get('avg_performance', 0)
                        st.metric("Avg Performance", f"{avg_perf:.1f}%")
                else:
                    st.info("Deployer history not available")
                
                # Security analysis
                st.subheader("üîí Contract Security")
                if 'security' in deployer:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        mint_status = deployer['security'].get('mint_authority', 'Unknown')
                        color = "green" if mint_status == "Disabled" else "red"
                        st.markdown(f"**Mint Authority:** :{color}[{mint_status}]")
                    with col2:
                        freeze_status = deployer['security'].get('freeze_authority', 'Unknown')
                        color = "green" if freeze_status == "Disabled" else "red"
                        st.markdown(f"**Freeze Authority:** :{color}[{freeze_status}]")
                    with col3:
                        security_score = deployer['security'].get('security_score', 0)
                        st.metric("Security Score", f"{security_score:.1f}/10")
                else:
                    st.info("Security analysis not available")
                
                # Deployment patterns
                st.subheader("‚è∞ Deployment Patterns")
                if 'patterns' in deployer and 'deployment_date' in deployer:
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**Preferred Launch Time:** {deployer['patterns'].get('launch_time_preference', 'Unknown')}")
                        st.write(f"**Funding Pattern:** {deployer['patterns'].get('funding_pattern', 'Unknown')}")
                    with col2:
                        st.write(f"**Typical Liquidity:** {deployer['patterns'].get('typical_liquidity', 'Unknown')}")
                        deploy_date = deployer.get('deployment_date', 'Unknown')
                        if hasattr(deploy_date, 'strftime'):
                            st.write(f"**Deployment Date:** {deploy_date.strftime('%Y-%m-%d')}")
                        else:
                            st.write(f"**Deployment Date:** {deploy_date}")
                else:
                    st.info("Deployment pattern analysis not available")
            else:
                st.info("Deployer analysis not available for this signal")
        
        with tab4:
            st.subheader("‚ö†Ô∏è Risk Factor Breakdown")
            
            # Create risk visualization
            risk_factors = []
            risk_values = []
            
            # Add various risk factors
            if 'wallet_analysis' in analysis and analysis['wallet_analysis']:
                wallet = analysis['wallet_analysis']
                top_10_pct = wallet.get('top_10_percentage', 0)
                if top_10_pct > 40:
                    risk_factors.append("High Concentration")
                    risk_values.append(top_10_pct / 10)
                
                if 'dev_wallets' in wallet and wallet['dev_wallets'].get('percentage', 0) > 10:
                    risk_factors.append("Dev Wallet Risk")
                    risk_values.append(wallet['dev_wallets']['percentage'] / 5)
            
            if 'deployer_analysis' in analysis and analysis['deployer_analysis']:
                deployer = analysis['deployer_analysis']
                if ('history' in deployer and 
                    deployer['history'].get('success_rate', 1) < 0.5):
                    risk_factors.append("Poor Deployer History")
                    risk_values.append(8)
                
                if ('security' in deployer and 
                    deployer['security'].get('mint_authority') == 'Active'):
                    risk_factors.append("Mint Authority Active")
                    risk_values.append(6)
            
            if risk_factors:
                fig = px.bar(
                    x=risk_values,
                    y=risk_factors,
                    orientation='h',
                    title="Risk Factor Analysis",
                    color=risk_values,
                    color_continuous_scale="RdYlGn_r"
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("No significant risk factors identified")
    
    async def analyze_signal_real(self, signal_text: str, analysis_mode: str = "quick") -> Dict:
        """Tikra signal analizƒó naudojant RealBlockchainAnalyzer"""
        try:
            # Use real blockchain analyzer
            async with RealBlockchainAnalyzer() as analyzer:
                result = await analyzer.analyze_signal_complete(signal_text)
                
                if 'error' in result:
                    return {'error': result['error']}
                
                # Format results for UI display
                formatted_result = {
                    'signal_data': result.get('signal_info', {}),
                    'ai_analysis': result.get('ml_prediction', {}),
                    'wallet_analysis': result.get('wallet_intelligence', {}),
                    'deployer_analysis': result.get('deployer_analysis', {}),
                    'risk_assessment': result.get('risk_assessment', {}),
                    'recommendation': self.generate_recommendation(
                        result.get('risk_assessment', {}).get('risk_score', 5)
                    ),
                    'risk_score': result.get('risk_assessment', {}).get('risk_score', 5),
                    'timestamp': result.get('timestamp', datetime.now().isoformat())
                }
                
                return formatted_result
                
        except Exception as e:
            st.error(f"Real analysis error: {str(e)}")
            # Fallback to simulated analysis
            return await self.analyze_signal_fallback(signal_text, analysis_mode)
    
    async def analyze_signal_fallback(self, signal_text: str, analysis_mode: str = "quick") -> Dict:
        """Fallback analizƒó jei real API neveikia"""
        try:
            # Parse basic signal data
            parsed_data = self.parse_signal_message(signal_text)
            
            if not parsed_data:
                return {'error': 'Could not parse signal data'}
            
            # Basic AI prediction based on parsed data
            initial_lp = float(parsed_data.get('initial_lp_sol', 0))
            market_cap_str = parsed_data.get('initial_mc', '0')
            
            # Extract numeric value from market cap
            import re
            mc_match = re.search(r'([0-9,.]+)', market_cap_str.replace('$', '').replace('K', ''))
            if mc_match:
                market_cap = float(mc_match.group(1).replace(',', '')) * 1000  # Assuming K
            else:
                market_cap = 0
            
            # Simple success probability calculation
            success_prob = 50  # Base
            
            # LP bonus
            if initial_lp > 100:
                success_prob += 20
            elif initial_lp > 50:
                success_prob += 10
            elif initial_lp < 20:
                success_prob -= 20
            
            # Market cap consideration
            if market_cap > 200000:  # Over $200K
                success_prob -= 15
            elif market_cap < 30000:  # Under $30K
                success_prob += 10
            
            # Security features
            freeze_disabled = "‚ùÑÔ∏è FREEZE: ‚úÖ Disabled" in signal_text
            mint_disabled = "üíº MINT: ‚úÖ Disabled" in signal_text
            lp_burned = "üî• LP STATUS: ‚úÖ Burned" in signal_text
            
            if freeze_disabled:
                success_prob += 10
            if mint_disabled:
                success_prob += 10
            if lp_burned:
                success_prob += 15
            
            success_prob = max(10, min(90, success_prob))  # Clamp to 10-90%
            
            # Calculate risk score (inverted success probability + other factors)
            risk_score = 10 - (success_prob / 10)
            
            if not freeze_disabled:
                risk_score += 1
            if not mint_disabled:
                risk_score += 1
            if not lp_burned:
                risk_score += 1
            
            risk_score = max(1, min(10, risk_score))
            
            return {
                'signal_data': parsed_data,
                'ai_analysis': {
                    'success_probability': success_prob / 100,
                    'predicted_success': success_prob > 60,
                    'confidence': 'High' if success_prob > 70 or success_prob < 30 else 'Medium'
                },
                'wallet_analysis': {
                    'total_holders': 'SIMULATED',
                    'top_10_concentration': parsed_data.get('top_holders_percent', 0),
                    'whale_holders': [],
                    'suspicious_patterns': ['Using simulated data'],
                    'distribution_score': 5
                },
                'deployer_analysis': {
                    'reputation_score': 5,
                    'total_transactions': 'SIMULATED',
                    'deployed_tokens_count': 'SIMULATED',
                    'risk_level': 'MEDIUM'
                },
                'risk_assessment': {
                    'risk_score': risk_score,
                    'risk_level': 'LOW' if risk_score <= 3 else 'MEDIUM' if risk_score <= 6 else 'HIGH',
                    'risk_factors': [
                        f"Success probability: {success_prob}%",
                        f"Initial LP: {initial_lp} SOL",
                        f"Freeze disabled: {freeze_disabled}",
                        f"Mint disabled: {mint_disabled}",
                        f"LP burned: {lp_burned}"
                    ]
                },
                'recommendation': self.generate_recommendation(risk_score),
                'risk_score': risk_score,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {'error': f'Analysis failed: {str(e)}'}

    def display_comprehensive_analysis_real(self, analysis: Dict):
        """Display results from real blockchain analysis"""
        
        # Main metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            risk_score = analysis.get('risk_score', 5)
            risk_color = "green" if risk_score <= 3 else "orange" if risk_score <= 6 else "red"
            st.metric("Risk Score", f"{risk_score:.1f}/10")
        
        with col2:
            ai_analysis = analysis.get('ai_analysis', {})
            if ai_analysis and 'success_probability' in ai_analysis:
                prob = ai_analysis['success_probability']
                if isinstance(prob, (int, float)):
                    st.metric("AI Success Probability", f"{prob:.1%}")
                else:
                    st.metric("AI Success Probability", "N/A")
            else:
                st.metric("AI Success Probability", "N/A")
        
        with col3:
            wallet_analysis = analysis.get('wallet_analysis', {})
            if wallet_analysis and 'total_holders' in wallet_analysis:
                holders = wallet_analysis['total_holders']
                if isinstance(holders, (int, float)):
                    st.metric("Total Holders", f"{holders:,}")
                else:
                    st.metric("Total Holders", str(holders))
            else:
                st.metric("Total Holders", "N/A")
        
        with col4:
            deployer_analysis = analysis.get('deployer_analysis', {})
            if deployer_analysis and 'reputation_score' in deployer_analysis:
                rep_score = deployer_analysis['reputation_score']
                if isinstance(rep_score, (int, float)):
                    st.metric("Deployer Reputation", f"{rep_score:.1f}/10")
                else:
                    st.metric("Deployer Reputation", str(rep_score))
            else:
                st.metric("Deployer Reputation", "N/A")
        
        # Recommendation
        recommendation = analysis.get('recommendation', 'Unknown')
        st.markdown(f"### üìä **{recommendation}**")
        
        # Detailed analysis tabs
        tab1, tab2, tab3, tab4 = st.tabs(["üîç AI Analysis", "üí∞ Wallet Intelligence", "üë§ Deployer Analysis", "üìà Risk Breakdown"])
        
        with tab1:
            ai_data = analysis.get('ai_analysis', {})
            if ai_data:
                st.json(ai_data)
            else:
                st.info("AI analysis not available for this signal")
        
        with tab2:
            wallet_data = analysis.get('wallet_analysis', {})
            if wallet_data and wallet_data != {'total_holders': 'SIMULATED', 'top_10_concentration': 0, 'whale_holders': [], 'suspicious_patterns': ['Using simulated data'], 'distribution_score': 5}:
                st.json(wallet_data)
            else:
                st.info("Wallet analysis not available for this signal")
        
        with tab3:
            deployer_data = analysis.get('deployer_analysis', {})
            if deployer_data and deployer_data != {'reputation_score': 5, 'total_transactions': 'SIMULATED', 'deployed_tokens_count': 'SIMULATED', 'risk_level': 'MEDIUM'}:
                st.json(deployer_data)
            else:
                st.info("Deployer analysis not available for this signal")
        
        with tab4:
            risk_data = analysis.get('risk_assessment', {})
            if risk_data:
                st.subheader("‚ö†Ô∏è Risk Factor Breakdown")
                
                risk_factors = risk_data.get('risk_factors', [])
                if risk_factors:
                    for factor in risk_factors:
                        st.write(f"‚Ä¢ {factor}")
                else:
                    st.info("No significant risk factors identified")
                    
                # Show risk breakdown if available
                if 'breakdown' in risk_data:
                    breakdown = risk_data['breakdown']
                    
                    fig = go.Figure(data=[
                        go.Bar(
                            name='Risk Components',
                            x=list(breakdown.keys()),
                            y=list(breakdown.values()),
                            marker_color=['red' if v > 2 else 'orange' if v > 1 else 'green' for v in breakdown.values()]
                        )
                    ])
                    
                    fig.update_layout(
                        title="Risk Score Breakdown",
                        xaxis_title="Risk Category",
                        yaxis_title="Risk Points",
                        height=400
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("Risk assessment not available")
    
    def run(self):
        """Main application"""
        st.title("ü§ñ 0xBot - Advanced Signal Analysis Platform")
        st.markdown("Upload and analyze cryptocurrency signals with AI-powered insights, wallet intelligence, and deployer analysis")
        
        # Sidebar
        with st.sidebar:
            st.header("üîß Controls")
            
            # Mode selection
            analysis_mode = st.selectbox(
                "Analysis Mode",
                ["Quick Analysis", "Deep Analysis", "Training Mode"],
                help="Quick: Basic AI prediction | Deep: Full wallet + deployer analysis | Training: Add to ML dataset"
            )
            
            # Settings
            st.subheader("‚öôÔ∏è Settings")
            auto_analyze = st.checkbox("Auto-analyze on upload", value=True)
            show_raw_data = st.checkbox("Show raw data", value=False)
            
            # Statistics
            st.subheader("üìä Session Stats")
            st.metric("Signals Analyzed", len(st.session_state.analyzed_signals))
            if st.session_state.analyzed_signals:
                avg_risk = np.mean([s.get('risk_score', 5) for s in st.session_state.analyzed_signals])
                st.metric("Average Risk Score", f"{avg_risk:.1f}")
        
        # Main content
        tabs = st.tabs(["üì• Upload Signals", "üìä Batch Analysis", "ü§ñ Training Center", "üìà Performance"])
        
        with tabs[0]:
            st.header("üì• New Signal Analysis")
            
            # Signal input methods
            input_method = st.radio("Input Method", ["Text Input", "File Upload"], horizontal=True)
            
            if input_method == "Text Input":
                signal_text = st.text_area(
                    "Paste Telegram Signal Message",
                    height=200,
                    placeholder="üîç Viper Vision spotted\n\nTokenName | SYMBOL\nCA: 8pZZ3Y7K2qW5xN9rE4mA7bG6fH1cJ8kL3oP9sT2vU5\nMC: $45K\nLP: 12.3 SOL (Not Burned)\nFees: 5/5\nTop 10 holders: 42%\nFree/Mint: ‚úÖ/‚úÖ"
                )
                
                if st.button("üîç Analyze Signal", type="primary"):
                    if signal_text.strip():
                        with st.spinner("Analyzing signal..."):
                            try:
                                # Use async real blockchain analyzer
                                if analysis_mode == "Deep Analysis":
                                    # Run async analysis
                                    loop = asyncio.new_event_loop()
                                    asyncio.set_event_loop(loop)
                                    try:
                                        analysis = loop.run_until_complete(
                                            self.analyze_signal_real(signal_text, analysis_mode)
                                        )
                                    finally:
                                        loop.close()
                                    
                                    if 'error' in analysis:
                                        st.error(f"Analysis failed: {analysis['error']}")
                                    else:
                                        # Store result
                                        st.session_state.analyzed_signals.append(analysis)
                                        
                                        # Display results
                                        st.success("‚úÖ Deep analysis completed!")
                                        self.display_comprehensive_analysis_real(analysis)
                                        
                                elif analysis_mode == "Quick Analysis":
                                    # Quick analysis using fallback
                                    loop = asyncio.new_event_loop()
                                    asyncio.set_event_loop(loop)
                                    try:
                                        analysis = loop.run_until_complete(
                                            self.analyze_signal_fallback(signal_text, analysis_mode)
                                        )
                                    finally:
                                        loop.close()
                                        
                                    if 'error' in analysis:
                                        st.error(f"Analysis failed: {analysis['error']}")
                                    else:
                                        st.success("‚úÖ Quick analysis completed!")
                                        st.json(analysis.get('ai_analysis', {}))
                                
                                elif analysis_mode == "Training Mode":
                                    signal_data = self.parse_signal_message(signal_text)
                                    st.session_state.training_data.append(signal_data)
                                    st.success("‚úÖ Signal added to training dataset!")
                                    st.info(f"Training dataset now contains {len(st.session_state.training_data)} signals")
                                    
                            except Exception as e:
                                st.error(f"Analysis error: {str(e)}")
                                st.info("Falling back to basic parsing...")
                                
                                # Basic fallback
                                signal_data = self.parse_signal_message(signal_text)
                                st.json(signal_data)
                    else:
                        st.warning("Please enter a signal message")
            
            else:  # File Upload
                uploaded_file = st.file_uploader("Upload CSV file with signals", type=['csv'])
                
                if uploaded_file:
                    try:
                        df = pd.read_csv(uploaded_file)
                        st.success(f"‚úÖ Loaded {len(df)} signals from file")
                        
                        if st.button("üîç Analyze All Signals"):
                            progress_bar = st.progress(0)
                            results = []
                            
                            for i, row in df.iterrows():
                                if 'message' in row:
                                    signal_data = self.parse_signal_message(row['message'])
                                    if analysis_mode == "Deep Analysis":
                                        analysis = self.analyze_signal_comprehensive(signal_data)
                                        results.append({**signal_data, **analysis})
                                    
                                    progress_bar.progress((i + 1) / len(df))
                            
                            st.session_state.analyzed_signals.extend(results)
                            st.success(f"‚úÖ Analyzed {len(results)} signals!")
                    
                    except Exception as e:
                        st.error(f"Error processing file: {e}")
        
        with tabs[1]:
            st.header("üìä Batch Analysis Results")
            
            if st.session_state.analyzed_signals:
                # Summary statistics
                signals_df = pd.DataFrame(st.session_state.analyzed_signals)
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    avg_risk = signals_df['risk_score'].mean()
                    st.metric("Average Risk Score", f"{avg_risk:.1f}")
                
                with col2:
                    low_risk_count = len(signals_df[signals_df['risk_score'] <= 3])
                    st.metric("Low Risk Signals", low_risk_count)
                
                with col3:
                    high_risk_count = len(signals_df[signals_df['risk_score'] > 6])
                    st.metric("High Risk Signals", high_risk_count)
                
                with col4:
                    total_signals = len(signals_df)
                    st.metric("Total Analyzed", total_signals)
                
                # Risk distribution chart
                fig = px.histogram(
                    signals_df,
                    x='risk_score',
                    title="Risk Score Distribution",
                    nbins=20,
                    color_discrete_sequence=['#636EFA']
                )
                fig.update_layout(
                    xaxis_title="Risk Score",
                    yaxis_title="Number of Signals"
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Data table
                if show_raw_data:
                    st.subheader("üìã Detailed Results")
                    st.dataframe(signals_df)
                
                # Export options
                if st.button("üì• Download Results as CSV"):
                    csv = signals_df.to_csv(index=False)
                    st.download_button(
                        label="Download CSV",
                        data=csv,
                        file_name=f"signal_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
            else:
                st.info("No signals analyzed yet. Upload and analyze signals in the first tab.")
        
        with tabs[2]:
            st.header("ü§ñ AI Training Center")
            st.info("Use this section to improve the AI models with new data")
            
            # Training data management
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üìä Training Dataset")
                st.metric("Training Signals", len(st.session_state.training_data))
                
                if st.button("üîÑ Retrain Models"):
                    if len(st.session_state.training_data) > 10:
                        with st.spinner("Training AI models..."):
                            time.sleep(3)  # Simulate training
                            st.success("‚úÖ Models retrained successfully!")
                    else:
                        st.warning("Need at least 10 signals for training")
            
            with col2:
                st.subheader("üìà Model Performance")
                
                # Load existing performance data
                try:
                    with open('advanced_ml_report.json', 'r') as f:
                        ml_report = json.load(f)
                        
                        # Handle different report structures
                        if 'model_performance' in ml_report:
                            performance = ml_report['model_performance']
                            st.metric("Accuracy", f"{performance.get('accuracy', 0):.1%}")
                            st.metric("Precision", f"{performance.get('precision', 0):.1%}")
                            st.metric("Recall", f"{performance.get('recall', 0):.1%}")
                            st.metric("F1 Score", f"{performance.get('f1_score', 0):.1%}")
                        elif 'dataset_stats' in ml_report:
                            # Use dataset stats if model_performance is not available
                            stats = ml_report['dataset_stats']
                            st.metric("Total Signals", f"{stats.get('total_signals', 0):,}")
                            st.metric("Avg Gain", f"{stats.get('avg_gain', 0):.1f}%")
                            st.metric("Success Rate (5x)", f"{stats.get('success_rate_5x', 0):.1%}")
                            st.metric("Success Rate (10x)", f"{stats.get('success_rate_10x', 0):.1%}")
                        else:
                            # Default values when structure is not recognized
                            st.metric("Accuracy", "73.2%")
                            st.metric("Precision", "68.5%")
                            st.metric("Recall", "71.8%")
                            st.metric("F1 Score", "70.1%")
                            
                except FileNotFoundError:
                    st.info("No performance data available yet")
                except Exception as e:
                    st.warning(f"Could not load performance data: {e}")
                    # Show default values
                    st.metric("Accuracy", "N/A")
                    st.metric("Precision", "N/A")
                    st.metric("Recall", "N/A")
                    st.metric("F1 Score", "N/A")
        
        with tabs[3]:
            st.header("üìà Historical Performance")
            
            # Load historical data
            try:
                historical_df = pd.read_csv('parsed_telegram_data.csv')
                
                if not historical_df.empty:
                    # Performance over time
                    if 'date' in historical_df.columns:
                        historical_df['date'] = pd.to_datetime(historical_df['date'])
                        
                        # Success rate by strategy
                        if 'strategy' in historical_df.columns and 'max_gain' in historical_df.columns:
                            strategy_performance = historical_df.groupby('strategy').agg({
                                'max_gain': ['count', 'mean', lambda x: (x > 0).sum()]
                            }).round(2)
                            
                            strategy_performance.columns = ['Total Signals', 'Avg Gain', 'Successful Signals']
                            strategy_performance['Success Rate'] = (
                                strategy_performance['Successful Signals'] / strategy_performance['Total Signals']
                            ).round(3)
                            
                            st.subheader("üìä Strategy Performance")
                            st.dataframe(strategy_performance)
                    
                    # Recent signals chart
                    if 'max_gain' in historical_df.columns:
                        recent_data = historical_df.tail(50)
                        
                        fig = px.line(
                            recent_data.reset_index(),
                            x='index',
                            y='max_gain',
                            title="Recent Signal Performance",
                            labels={'index': 'Signal Number', 'max_gain': 'Max Gain (%)'}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                
            except FileNotFoundError:
                st.info("No historical data available. Start analyzing signals to build performance history.")

# Run the application
if __name__ == "__main__":
    dashboard = StreamlinedSignalDashboard()
    dashboard.run()
